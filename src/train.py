#!/usr/bin/env python3
"""
Script d'entraÃ®nement principal pour les modÃ¨les de prÃ©diction Bitcoin
Utilise la structure modulaire du projet
"""

import os
import time
import numpy as np
from datetime import datetime
from sklearn.model_selection import train_test_split

# Imports des modules du projet
from data.collector import collect_data_crypto_compare, preprocess_data
from features.preprocessing import prepare_training_data
from models.cnn_bilstm import build_gru_model, build_cnn_bilstm_model, get_early_stopping
from utils.visualization import plot_predictions, plot_training_history, print_metrics


def train_gru_model(data, seq_length=32, units=128, dropout=0.1, learning_rate=0.01, 
                   validation_split=0.2, epochs=100, batch_size=32):
    """
    EntraÃ®ne un modÃ¨le GRU pour la prÃ©diction du prix Bitcoin
    
    Args:
        data: DataFrame avec les donnÃ©es prÃ©traitÃ©es
        seq_length: Longueur des sÃ©quences
        units: Nombre d'unitÃ©s GRU
        dropout: Taux de dropout
        learning_rate: Taux d'apprentissage
        validation_split: Proportion des donnÃ©es pour la validation
        epochs: Nombre d'epochs
        batch_size: Taille des batches
    
    Returns:
        Tuple (model, history, metrics)
    """
    print("ğŸš€ DÃ©but de l'entraÃ®nement du modÃ¨le GRU...")
    
    # PrÃ©paration des donnÃ©es
    X, y, eth_scaler, btc_scaler = prepare_training_data(data, seq_length)
    
    # Division train/test
    train_size = int(len(X) * (1 - validation_split))
    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]
    
    print(f"ğŸ“Š DonnÃ©es d'entraÃ®nement: {len(X_train)} Ã©chantillons")
    print(f"ğŸ“Š DonnÃ©es de test: {len(X_test)} Ã©chantillons")
    
    # Construction du modÃ¨le
    model = build_gru_model(seq_length, units, dropout, learning_rate)
    early_stop = get_early_stopping(patience=15)
    
    print("ğŸ—ï¸ Architecture du modÃ¨le:")
    model.summary()
    
    # EntraÃ®nement
    print("\nğŸ¯ DÃ©but de l'entraÃ®nement...")
    start_time = time.time()
    
    history = model.fit(
        X_train, y_train,
        epochs=epochs,
        batch_size=batch_size,
        validation_split=0.2,
        callbacks=[early_stop],
        verbose=1
    )
    
    training_time = time.time() - start_time
    print(f"â±ï¸ Temps d'entraÃ®nement: {training_time:.2f} secondes")
    
    # PrÃ©dictions et Ã©valuation
    print("\nğŸ” Ã‰valuation du modÃ¨le...")
    y_pred = model.predict(X_test, verbose=0)
    
    # DÃ©-normalisation
    y_test_inv = btc_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
    y_pred_inv = btc_scaler.inverse_transform(y_pred).flatten()
    
    # MÃ©triques
    print_metrics(y_test_inv, y_pred_inv)
    
    # Visualisations
    test_dates = data['time'].iloc[-len(y_test):].values
    plot_predictions(y_test_inv, y_pred_inv, test_dates, "PrÃ©diction GRU - Prix Bitcoin")
    plot_training_history(history)
    
    return model, history, (y_test_inv, y_pred_inv)


def train_cnn_bilstm_model(data, seq_length=32, filters=64, lstm_units=50, dropout=0.2, 
                          validation_split=0.2, epochs=100, batch_size=32):
    """
    EntraÃ®ne un modÃ¨le CNN-BiLSTM pour la prÃ©diction du prix Bitcoin
    
    Args:
        data: DataFrame avec les donnÃ©es prÃ©traitÃ©es
        seq_length: Longueur des sÃ©quences
        filters: Nombre de filtres CNN
        lstm_units: Nombre d'unitÃ©s LSTM
        dropout: Taux de dropout
        validation_split: Proportion des donnÃ©es pour la validation
        epochs: Nombre d'epochs
        batch_size: Taille des batches
    
    Returns:
        Tuple (model, history, metrics)
    """
    print("ğŸš€ DÃ©but de l'entraÃ®nement du modÃ¨le CNN-BiLSTM...")
    
    # PrÃ©paration des donnÃ©es
    X, y, eth_scaler, btc_scaler = prepare_training_data(data, seq_length)
    
    # Division train/test
    train_size = int(len(X) * (1 - validation_split))
    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]
    
    print(f"ğŸ“Š DonnÃ©es d'entraÃ®nement: {len(X_train)} Ã©chantillons")
    print(f"ğŸ“Š DonnÃ©es de test: {len(X_test)} Ã©chantillons")
    
    # Construction du modÃ¨le
    model = build_cnn_bilstm_model(seq_length, filters, lstm_units, dropout)
    early_stop = get_early_stopping(patience=20)
    
    print("ğŸ—ï¸ Architecture du modÃ¨le:")
    model.summary()
    
    # EntraÃ®nement
    print("\nğŸ¯ DÃ©but de l'entraÃ®nement...")
    start_time = time.time()
    
    history = model.fit(
        X_train, y_train,
        epochs=epochs,
        batch_size=batch_size,
        validation_split=0.2,
        callbacks=[early_stop],
        verbose=1
    )
    
    training_time = time.time() - start_time
    print(f"â±ï¸ Temps d'entraÃ®nement: {training_time:.2f} secondes")
    
    # PrÃ©dictions et Ã©valuation
    print("\nğŸ” Ã‰valuation du modÃ¨le...")
    y_pred = model.predict(X_test, verbose=0)
    
    # DÃ©-normalisation
    y_test_inv = btc_scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
    y_pred_inv = btc_scaler.inverse_transform(y_pred).flatten()
    
    # MÃ©triques
    print_metrics(y_test_inv, y_pred_inv)
    
    # Visualisations
    test_dates = data['time'].iloc[-len(y_test):].values
    plot_predictions(y_test_inv, y_pred_inv, test_dates, "PrÃ©diction CNN-BiLSTM - Prix Bitcoin")
    plot_training_history(history)
    
    return model, history, (y_test_inv, y_pred_inv)


def compare_models(data):
    """
    Compare les performances des diffÃ©rents modÃ¨les
    
    Args:
        data: DataFrame avec les donnÃ©es prÃ©traitÃ©es
    """
    print("\n" + "="*60)
    print("ğŸ† COMPARAISON DES MODÃˆLES")
    print("="*60)
    
    models_results = []
    
    # EntraÃ®nement GRU
    print("\n1ï¸âƒ£ EntraÃ®nement du modÃ¨le GRU...")
    gru_model, gru_history, gru_predictions = train_gru_model(data)
    models_results.append(("GRU", gru_model, gru_predictions))
    
    # Sauvegarde GRU
    gru_model.save("../models/gru_model.h5")
    print("âœ… ModÃ¨le GRU sauvegardÃ©: models/gru_model.h5")
    
    # EntraÃ®nement CNN-BiLSTM
    print("\n2ï¸âƒ£ EntraÃ®nement du modÃ¨le CNN-BiLSTM...")
    cnn_model, cnn_history, cnn_predictions = train_cnn_bilstm_model(data)
    models_results.append(("CNN-BiLSTM", cnn_model, cnn_predictions))
    
    # Sauvegarde CNN-BiLSTM
    cnn_model.save("../models/cnn_bilstm_model.h5")
    print("âœ… ModÃ¨le CNN-BiLSTM sauvegardÃ©: models/cnn_bilstm_model.h5")
    
    # Comparaison finale
    print("\n" + "="*60)
    print("ğŸ“Š RÃ‰SULTATS FINAUX")
    print("="*60)
    
    best_model = None
    best_r2 = -float('inf')
    best_model_name = ""
    
    for model_name, model, (y_true, y_pred) in models_results:
        from utils.visualization import calculate_metrics
        metrics = calculate_metrics(y_true, y_pred)
        
        print(f"\nğŸ¤– {model_name}:")
        print(f"   RMSE: ${metrics['RMSE']:,.2f}")
        print(f"   RÂ²:   {metrics['RÂ²']:.4f}")
        print(f"   MAE:  ${metrics['MAE']:,.2f}")
        
        if metrics['RÂ²'] > best_r2:
            best_r2 = metrics['RÂ²']
            best_model = model
            best_model_name = model_name
    
    # Sauvegarde du meilleur modÃ¨le
    print(f"\nğŸ† Le meilleur modÃ¨le est: {best_model_name} (RÂ² = {best_r2:.4f})")
    best_model.save("../models/best_model.h5")
    print("âœ… Meilleur modÃ¨le sauvegardÃ©: models/best_model.h5")
    
    return models_results, best_model, best_model_name


def main():
    """
    Fonction principale d'exÃ©cution du script d'entraÃ®nement
    """
    print("ğŸš€ DÃ‰MARRAGE DU SCRIPT D'ENTRAÃNEMENT BITCOIN")
    print("="*60)
    
    # Collecte des donnÃ©es
    print("\nğŸ“¡ Collecte des donnÃ©es...")
    btc_data = collect_data_crypto_compare('BTC', days=365)
    eth_data = collect_data_crypto_compare('ETH', days=365)
    
    if btc_data is None or eth_data is None:
        print("âŒ Erreur lors de la collecte des donnÃ©es")
        return
    
    print(f"âœ… DonnÃ©es BTC collectÃ©es: {len(btc_data)} jours")
    print(f"âœ… DonnÃ©es ETH collectÃ©es: {len(eth_data)} jours")
    
    # PrÃ©traitement des donnÃ©es
    print("\nğŸ”§ PrÃ©traitement des donnÃ©es...")
    combined_data = preprocess_data(btc_data, eth_data)
    
    if combined_data is None:
        print("âŒ Erreur lors du prÃ©traitement des donnÃ©es")
        return
    
    print(f"âœ… DonnÃ©es prÃ©traitÃ©es: {len(combined_data)} Ã©chantillons")
    
    # CrÃ©er le dossier models s'il n'existe pas
    os.makedirs("../models", exist_ok=True)
    
    # Comparaison des modÃ¨les
    models_results, best_model, best_model_name = compare_models(combined_data)
    
    # RÃ©sumÃ© final
    print("\n" + "="*60)
    print("ğŸ‰ ENTRAÃNEMENT TERMINÃ‰ AVEC SUCCÃˆS!")
    print("="*60)
    print(f"ğŸ† Meilleur modÃ¨le: {best_model_name}")
    print(f"ğŸ“ ModÃ¨les sauvegardÃ©s dans: ../models/")
    print(f"ğŸ“Š Nombre total de modÃ¨les entraÃ®nÃ©s: {len(models_results)}")
    
    # Affichage des prochaines Ã©tapes
    print("\nğŸ’¡ PROCHAINES Ã‰TAPES:")
    print("   1. Utilisez le meilleur modÃ¨le pour faire des prÃ©dictions")
    print("   2. Testez les modÃ¨les avec de nouvelles donnÃ©es")
    print("   3. DÃ©ployez l'application Streamlit avec app.py")
    print("   4. Surveillez les performances en temps rÃ©el")
    
    print(f"\nâ° Script terminÃ© Ã : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nâš ï¸ EntraÃ®nement interrompu par l'utilisateur")
    except Exception as e:
        print(f"\nâŒ Erreur inattendue: {e}")
        import traceback
        traceback.print_exc()
